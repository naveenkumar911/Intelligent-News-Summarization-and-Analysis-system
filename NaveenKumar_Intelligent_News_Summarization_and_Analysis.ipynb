{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Intelligent News Summarization and Analysis system"
      ],
      "metadata": {
        "id": "JeJjlY291PEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Description:\n",
        "- The implementation integrates NewsAPI, OpenAI GPT API (via LangChain for simplified prompt management), FastAPI for API handling, and other essential libraries for processing, caching, and managing the pipeline."
      ],
      "metadata": {
        "id": "0Y3xFn9S1e5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Developed By : Naveen Kumar"
      ],
      "metadata": {
        "id": "IkFXUiVU1T6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install the necessary libraries"
      ],
      "metadata": {
        "id": "_7FBbYJF1t_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUwjahopzhbt"
      },
      "outputs": [],
      "source": [
        "!pip install newsapi-python langchain openai fastapi uvicorn beautifulsoup4 requests\n",
        "!pip install -q fastapi-cache2 pytest docker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from newsapi import NewsApiClient\n",
        "from fastapi import FastAPI, HTTPException, Query\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List, Dict, Any\n",
        "from fastapi_cache import caches, close_caches\n",
        "from fastapi_cache.backends.inmemory import InMemoryCacheBackend\n",
        "import uvicorn\n",
        "import re\n",
        "from datetime import datetime\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "EnEyYa_IzwoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##API Integration"
      ],
      "metadata": {
        "id": "Y8Dtayor3w0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialize NewsAPI and OpenAI API clients"
      ],
      "metadata": {
        "id": "nhXjr6ie14Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NEWS_API_KEY = \"YOUR_NEWSAPI_KEY\"\n",
        "OPENAI_API_KEY = \"YOUR_OPENAI_KEY\"\n",
        "newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
        "llm = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "s0z6IY--z1At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize FastAPI and caching"
      ],
      "metadata": {
        "id": "RgHoaUBw19bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "caches.set(InMemoryCacheBackend())"
      ],
      "metadata": {
        "id": "7BuY7zGrz0uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Collection"
      ],
      "metadata": {
        "id": "rZBWHr3W3qCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fetching news articles"
      ],
      "metadata": {
        "id": "xamI3RnS2C5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for fetching news articles\n",
        "async def fetch_news(query: str, page_size: int = 5) -> List[Dict[str, Any]]:\n",
        "    try:\n",
        "        articles = newsapi.get_everything(q=query, language=\"en\", page_size=page_size)\n",
        "        return articles[\"articles\"]\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "upFfHwMJ0D7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Article processing"
      ],
      "metadata": {
        "id": "9gD_0ZVp2Grs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for article processing\n",
        "def process_article(article: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    content = article.get(\"content\", \"\")\n",
        "    cleaned_content = re.sub(r'\\W+', ' ', content)\n",
        "    article_data = {\n",
        "        \"title\": article[\"title\"],\n",
        "        \"date\": article[\"publishedAt\"],\n",
        "        \"content\": cleaned_content,\n",
        "        \"source\": article[\"source\"][\"name\"]\n",
        "    }\n",
        "    return article_data"
      ],
      "metadata": {
        "id": "VKgCr7hY0DNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prompt templates"
      ],
      "metadata": {
        "id": "mKjGN6262QU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt templates for each LLM task\n",
        "summary_prompt = PromptTemplate(\"Summarize the following article: {content}\")"
      ],
      "metadata": {
        "id": "65FjssM50C3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_prompt = PromptTemplate(\"Extract key points from this article: {content}\")"
      ],
      "metadata": {
        "id": "0oostNJW2TJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_prompt = PromptTemplate(\"Analyze the sentiment of the article: {content}\")"
      ],
      "metadata": {
        "id": "Cr2ItlyO2VZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_prompt = PromptTemplate(\"Classify the main topic of the article: {content}\")"
      ],
      "metadata": {
        "id": "f1k-ApG92W6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LLM Integration"
      ],
      "metadata": {
        "id": "4iT2Bz_03f-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Interaction with LLM"
      ],
      "metadata": {
        "id": "jyg7w6wZ2f5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to interact with LLM for tasks\n",
        "async def analyze_article_with_llm(content: str) -> Dict[str, str]:\n",
        "    tasks = {\n",
        "        \"summary\": summary_prompt.generate(content=content),\n",
        "        \"key_points\": key_points_prompt.generate(content=content),\n",
        "        \"sentiment\": sentiment_prompt.generate(content=content),\n",
        "        \"topic\": topic_prompt.generate(content=content)\n",
        "    }\n",
        "    results = await asyncio.gather(\n",
        "        llm(tasks[\"summary\"]),\n",
        "        llm(tasks[\"key_points\"]),\n",
        "        llm(tasks[\"sentiment\"]),\n",
        "        llm(tasks[\"topic\"])\n",
        "    )\n",
        "    return {\n",
        "        \"summary\": results[0],\n",
        "        \"key_points\": results[1],\n",
        "        \"sentiment\": results[2],\n",
        "        \"topic\": results[3]\n",
        "    }"
      ],
      "metadata": {
        "id": "_vCa_LUq0S9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###API Development"
      ],
      "metadata": {
        "id": "V21TshQZ3Xwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Asynchronous endpoints"
      ],
      "metadata": {
        "id": "kAwykUF72k6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asynchronous endpoint for fetching and analyzing articles\n",
        "@app.get(\"/news/\")\n",
        "async def get_news(query: str = Query(..., min_length=2)):\n",
        "    cached_data = await caches.get(\"news_cache\", key=query)\n",
        "    if cached_data:\n",
        "        return cached_data\n",
        "\n",
        "    articles = await fetch_news(query)\n",
        "    if not articles:\n",
        "        raise HTTPException(status_code=404, detail=\"No articles found.\")\n",
        "\n",
        "    processed_articles = []\n",
        "    for article in articles:\n",
        "        data = process_article(article)\n",
        "        analysis = await analyze_article_with_llm(data[\"content\"])\n",
        "        processed_articles.append({**data, **analysis})\n",
        "\n",
        "    await caches.set(\"news_cache\", key=query, value=processed_articles, ttl=300)\n",
        "    return processed_articles\n"
      ],
      "metadata": {
        "id": "Hb44AFNO0YBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Endpoint to retrieve trending topics\n",
        "@app.get(\"/trending/\")\n",
        "async def get_trending_topics():\n",
        "    # Placeholder for actual trending topic extraction\n",
        "    return {\"topics\": [\"technology\", \"business\", \"politics\"]}\n"
      ],
      "metadata": {
        "id": "MuiTzYoi0ckI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FastAPI Caching"
      ],
      "metadata": {
        "id": "u1DTR0oq2s6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caching setup for FastAPI\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    await caches.init()\n",
        "\n",
        "@app.on_event(\"shutdown\")\n",
        "async def shutdown_event():\n",
        "    await close_caches()\n"
      ],
      "metadata": {
        "id": "T9-Om7V10cfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Docker Setup"
      ],
      "metadata": {
        "id": "x9Uit9ec2xCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dockerfile configuration\n",
        "DOCKERFILE = \"\"\"\n",
        "# Use official Python image as a base image\n",
        "FROM python:3.9\n",
        "\n",
        "# Set the working directory\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy the requirements file and install dependencies\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Copy the application code\n",
        "COPY . .\n",
        "\n",
        "# Expose port 8000 and run the FastAPI app\n",
        "EXPOSE 8000\n",
        "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "b1wJJ0-I0cXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Unit Testing"
      ],
      "metadata": {
        "id": "vVowAUu421og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit tests\n",
        "def test_process_article():\n",
        "    article = {\"title\": \"Test\", \"publishedAt\": \"2023-01-01\", \"content\": \"Some content\", \"source\": {\"name\": \"Test Source\"}}\n",
        "    processed = process_article(article)\n",
        "    assert processed[\"title\"] == \"Test\"\n",
        "    assert processed[\"date\"] == \"2023-01-01\"\n"
      ],
      "metadata": {
        "id": "4FgLYmwC0mQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run unit tests with pytest\n",
        "!echo \"test_process_article()\" > test_script.py\n",
        "!pytest test_script.py > result.log"
      ],
      "metadata": {
        "id": "jL0er3Qc0pMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving the Output"
      ],
      "metadata": {
        "id": "KAE6GG-a248e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dockerfile output to save to file\n",
        "with open(\"Dockerfile\", \"w\") as f:\n",
        "    f.write(DOCKERFILE)"
      ],
      "metadata": {
        "id": "AMhDjlvc0r8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run the FastAPI server locally"
      ],
      "metadata": {
        "id": "mvNQmRSr3DZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uvicorn main:app --reload --host 0.0.0.0 --port 8000"
      ],
      "metadata": {
        "id": "k-rT7zXR0vlw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}